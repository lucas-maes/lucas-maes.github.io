---
layout: page
---

<span class="pp" style="text-align:center; display:block; margin-top:-30px;">
![My face](https://avatars.githubusercontent.com/u/43337476?s=400&u=935f09908f80e0f67374ae1f8d4f6f0c6ee39c17&v=4)
</span>

<div style="text-align:center; margin-bottom: 10px;">
    <ul class="sub-nav">
        <li class="sub-item"><a href="https://github.com/lucas-maes" target="_blank">Github</a></li>
        <li class="sub-item"><a href="https://twitter.com/lucasmaes_" target="_blank">Twitter</a></li>
        <li class="sub-item"><a href="mailto:lucas.maes@mila.quebec">Email</a></li>
    </ul>
    <span class="email"> lucas.maes [AT] mila.quebec </span>
</div>

## About me

I am a second year PhD student at [Mila](https://www.mila.quebec/") and the Université de Montréal, supervised by [Damien Scieur](https://damienscieur.com/).

My research lies at the intersection of Self-Supervised Learning (SSL), Applied Mathematics, and Systems Design. I primarily focus on optimizing the training efficiency and scalability of SSL methods (see [predoc report](https://drive.google.com/file/d/1N1vqjEglwB_X_USQYAnHGDtmcNbVRYOT/view?usp=drive_link)), with a particular emphasis on Joint [Embedding Predictive Architectures (JEPA)]((https://openreview.net/pdf?id=BZ5a1r-kVsf)). I am particularly drawn to JEPA, proposed by Yann LeCun, as I believe it represents a promising direction for the future of AI systems.

My work is motivated by the observation that current AI systems [lack robust physical understanding](https://www.youtube.com/watch?v=NVxcsekcbhs) and real-world representations—capabilities that could be acquired through sophisticated [world models](https://arxiv.org/pdf/2403.00504). I hypothesize that video, with its rich informational content, is an ideal modality for [learning]((https://openreview.net/pdf?id=BZ5a1r-kVsf)) such world models. Currently, I am investigating [V-JEPA](https://openreview.net/pdf?id=WFYbBOEOtv) architectures, working to reduce their training costs and improve scalability to accelerate the development of effective world-modeling agents.


### Recommended Readings (Winter 2025)

I'd like to share some recent papers that I find particularly compelling and relevant to today's SSL research landscape. Whether you're interested in theoretical foundations or practical implementations, these papers provide valuable insights.

[DINO-WM: World Models On Pre-Trained Visual Features Enable Zero-Shot Planning](https://arxiv.org/pdf/2411.04983) - A groundbreaking demonstration of task-agnostic SSL world model. The authors achieved remarkable results across diverse environments through test-time planning and action sequence optimization. This work highlights how inference and planning deserve greater attention in the field.

[A Cookbook of Self-Supervised Learning](https://arxiv.org/pdf/2304.12210) - An *essential resource* for anyone working in self-supervised learning. While the literature review may not cover the most recent developments, the paper's true value lies in its comprehensive collection of practical implementation techniques used by practitioners. It reveals how the seemingly simple concept of self-supervised learning requires careful attention to numerous implementation details for successful deployment.

[The Llama 3 Herd of Models](https://arxiv.org/abs/2407.21783) - Masterclass in the intricacies of LLM training at scale offering invaluable insights into the practical challenges and solutions in modern realistic model training.


[On the Geometry of Deep Learning](https://arxiv.org/pdf/2408.04809) - An insightful synthesis of [Randall Balestriero](https://scholar.google.com/citations?user=S1x_xqcAAAAJ&hl=en)'s contributions to understanding deep learning through the lens of spline theory. This comprehensive review illuminates the geometric principles underlying neural networks and their behavior.

[On the Limitations of Elo: Real-World Games, are Transitive, not Additive](https://arxiv.org/abs/2206.12301) - A crucial contribution given the rising prominence of agentic AI. This work tackle the limits of ELO rating system opening a path for better comparison between AI agents.

### Academic Service

I am deeply committed to knowledge sharing in ML through co-organizing [MTLMLOpt](https://mtl-mlopt.github.io/) (a biweekly seminar series on deep learning and optimization), co-creating the [Mila Optimization CrashCourse](https://mila-optim.github.io/) for graduate students, and reviewing for the [Montreal AI Symposium](http://montrealaisymposium.com).



<p class="copyright"> Theme from <a href="https://atcold.github.io/">Alfredo Canziani</a>.  <span class="last-edit" style='float:right;'>Last update: 03 Jan 2025.</span></p>
